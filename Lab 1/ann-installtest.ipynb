{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1 style=\"font-size:40px;\"><center>Exercise 0:<br>Testing your installed enviroment\n",
        "</center></h1>\n",
        "\n",
        "# Introduction\n",
        "\n",
        "This is a very short notebook that test some of the things you'll be using for the computer exercises.\n",
        "\n",
        "## Last but not least\n",
        "Have fun!\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Importing some packages\n",
        "\n",
        "In the cell below, we will import needed libraries. \n",
        "\n",
        "Run the cell by entering into the cell and press \"CTRL Enter\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "device = 'cpu'\n",
        "# Uncomment this to use CUDA acceleration if available\n",
        "# device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
        "print(f\"PyTorch: Using {device} device\")\n",
        "# The floating point data type can be changed here\n",
        "dtype_torch = torch.float32\n",
        "\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch import nn, Tensor\n",
        "from collections import OrderedDict\n",
        "import torchmetrics\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "slideshow": {
          "slide_type": ""
        },
        "tags": []
      },
      "source": [
        "# Generate and display some data\n",
        "This cell defines the two synthetic datasets.\n",
        "Run the cell by entering into the cell and press \"CTRL Enter\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def syn2(N):\n",
        "    \"Generate data for classification problem in 2D.\"\n",
        "    x = np.empty(shape=(N, 2))\n",
        "    d = np.empty(shape=(N, 1))\n",
        "    N1 = N // 2\n",
        "\n",
        "    # Positive samples\n",
        "    x[:N1,:] = 0.8 + np.random.normal(size=(N1, 2))\n",
        "    # Negative samples\n",
        "    x[N1:,:] = -.8 + np.random.normal(size=(N-N1, 2))\n",
        "\n",
        "    # Target\n",
        "    d[:N1] = 1\n",
        "    d[N1:] = 0\n",
        "\n",
        "    return x, d\n",
        "\n",
        "def regr1(N, periods=2, damp=False, v=0):\n",
        "    \"Generate data for 1D regression problem with damped cosine and noise\"\n",
        "    dx = 2*periods*np.pi / (N-1)\n",
        "    x = np.arange(N) * dx\n",
        "\n",
        "    if damp:\n",
        "        d = np.cos(x)*np.exp(-x*0.05)\n",
        "    else:\n",
        "        d = np.cos(x)\n",
        "    noise = lambda n : np.random.normal(size=n)\n",
        "    std_signal = np.std(d)\n",
        "    d = d + v * std_signal * noise(N)\n",
        "\n",
        "    return x[:, None], d[:, None]\n",
        "\n",
        "def standard(x):\n",
        "    \"Mean and stddev across samples\"\n",
        "    return np.mean(x, axis=0), np.std(x, axis=0)\n",
        "\n",
        "# seed = 0 means random, seed > 0 means fixed\n",
        "seed = 0\n",
        "np.random.seed(seed) if seed else None\n",
        "\n",
        "x, d = syn2(100)\n",
        "plt.figure()\n",
        "plt.scatter(x[:,0], x[:,1], c=d)\n",
        "\n",
        "# Regression, one period, no noise\n",
        "x, d = regr1(100, 2, False, 0)\n",
        "plt.figure()\n",
        "plt.scatter(x, d)\n",
        "\n",
        "# Regression, 1.5 period, exponential damping, some noise\n",
        "x, d = regr1(100, 3, True, 0.2)\n",
        "plt.figure()\n",
        "plt.scatter(x, d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ANN test\n",
        "     \n",
        "Run the cell by entering into the cell and press \"CTRL Enter\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "class Network(nn.Module):\n",
        "    \"A simple MLP with one or more fully connected layers\"\n",
        "\n",
        "    def __init__(self, *, inputs=1, outputs=1, nodes=[4], activation=nn.Tanh, out_activation=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            inputs (int, optional): The number of input nodes.\n",
        "            outputs (int, optional): The number of output nodes.\n",
        "            nodes (list, optional): A list of layer sizes.\n",
        "            activation: Activation function (or None for linear). Defaults to nn.Tanh\n",
        "            out_activation (optional): Activation function for output layer.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        seqstack = OrderedDict()\n",
        "        prevn = inputs\n",
        "        for i, n in enumerate(nodes):\n",
        "            seqstack[f\"layer{i+1}\"] = nn.Linear(prevn, n, dtype=dtype_torch)\n",
        "            prevn = n\n",
        "            if activation is not None:\n",
        "                seqstack[f\"act{i+1}\"] = activation()\n",
        "        seqstack[\"layerN\"] = nn.Linear(prevn, outputs, dtype=dtype_torch)\n",
        "        if out_activation is not None:\n",
        "            seqstack[\"actN\"] = out_activation()\n",
        "        self.mlp_stack = nn.Sequential(seqstack)\n",
        "\n",
        "    def forward(self, x : Tensor):\n",
        "        \"Apply the network stack on some input\"\n",
        "        return self.mlp_stack(x)\n",
        "\n",
        "    def predict(self, input_data):\n",
        "        \"\"\"\n",
        "        Apply the network on a set of input data.\n",
        "\n",
        "        Args:\n",
        "            input_data (np.ndarray): Input data\n",
        "\n",
        "        Returns:\n",
        "            pred (np.ndarray): Predicted output.\n",
        "        \"\"\"\n",
        "        self.eval()\n",
        "        inp = torch.tensor(input_data, dtype=dtype_torch, device=device)\n",
        "        with torch.no_grad():\n",
        "            pred = self(inp)\n",
        "        return pred.cpu().numpy()\n",
        "\n",
        "    def __str__(self):\n",
        "        s = super().__str__()\n",
        "        ps = [\"Named parameters:\"] + [\n",
        "            f\"{name}: {param.numel()}\" for name, param in\n",
        "             self.mlp_stack.named_parameters() if param.requires_grad]\n",
        "        totp = sum(p.numel() for p in self.mlp_stack.parameters() if p.requires_grad)\n",
        "        return s + f\"\\nTrainable parameters: {totp}\\n\" + \"\\n  \".join(ps) + \"\\n\"\n",
        "\n",
        "def train_epoch(*, model : Network, dataloader : DataLoader,\n",
        "                loss_fn, optimizer : torch.optim.Optimizer):\n",
        "    \"\"\"\n",
        "    Train a model for a single epoch.\n",
        "\n",
        "    Args:\n",
        "        model (Network): The network.\n",
        "        dataloader (DataLoader): Batch DataLoader with training data.\n",
        "        loss_fn (Loss): Loss function, e.g. nn.MSELoss.\n",
        "        optimizer (Optimizer): The optimizer used to update the network.\n",
        "\n",
        "    Returns:\n",
        "        train_loss (float): Training error over all batches.\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for X, y in dataloader:\n",
        "        X, y = X.to(device), y.to(device)   # Move data to GPU if necessary\n",
        "        optimizer.zero_grad()   # Reset the gradients\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "        train_loss += loss.item() * len(X)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    return train_loss / len(dataloader.dataset)\n",
        "\n",
        "def test(*, model : Network, dataloader : DataLoader, loss_fn, metrics=[]):\n",
        "    \"\"\"\n",
        "    Test a model on a set of data.\n",
        "\n",
        "    Args:\n",
        "        model (Network): The network.\n",
        "        dataloader (DataLoader): DataLoader with data to test.\n",
        "        loss_fn (Loss): Loss function, e.g. nn.MSELoss.\n",
        "        metrics (iterable): Additional metrics from torchmetrics.\n",
        "\n",
        "    Returns:\n",
        "        loss (float): Mean error over all batches.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    loss = 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            loss += loss_fn(pred, y).item() * len(X)\n",
        "            for m in metrics:\n",
        "                m.update(pred, y)\n",
        "    return loss / len(dataloader.dataset)\n",
        "\n",
        "\n",
        "def train_loop(*, model : Network, train_dataloader : DataLoader,\n",
        "               val_dataloader : DataLoader = None, loss_fn,\n",
        "               optimizer : torch.optim.Optimizer, epochs : int,\n",
        "               print_every:int = 100, metrics=None, print_final=True):\n",
        "    \"\"\"\n",
        "    Train and optionally test a model.\n",
        "\n",
        "    Args:\n",
        "        model (Network): The network.\n",
        "        train_dataloader (DataLoader): Training data.\n",
        "        val_dataloader (DataLoader, optional): Validation data.\n",
        "        loss_fn (Loss): Loss function, e.g. nn.MSELoss.\n",
        "        optimizer (Optimizer): An optimizer from torch.optim.\n",
        "        epochs (int): Number of epochs to train for.\n",
        "        print_every (int, optional): Print loss every so many epochs. Defaults to 100.\n",
        "        metrics (dict(name: metric), optional): Record/print these additional metrics.\n",
        "        print_final(bool, optional): Print final metrics. Defaults to True.\n",
        "\n",
        "    Returns:\n",
        "        train_losses (list(float)): Training loss during each epoch.\n",
        "        val_losses (list(float)): Validation loss after each epoch.\n",
        "        metrics_res (dict(name: list(float))): Values of metrics after each epoch.\n",
        "    \"\"\"\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_loss = np.nan\n",
        "\n",
        "    # Move metrics to CPU/GPU and prepare for their output\n",
        "    metrics = {name: m.to(device) for name, m in (metrics or {}).items()}\n",
        "    metrics_res = {name: [] for name in metrics.keys()}\n",
        "\n",
        "    for t in range(epochs):\n",
        "        train_loss = train_epoch(model=model, dataloader=train_dataloader,\n",
        "                           loss_fn=loss_fn, optimizer=optimizer)\n",
        "        train_losses.append(train_loss)\n",
        "        if val_dataloader is not None:\n",
        "            for m in metrics.values():\n",
        "                m.reset()\n",
        "            val_loss = test(dataloader=val_dataloader, model=model,\n",
        "                            loss_fn=loss_fn, metrics=metrics.values())\n",
        "            val_losses.append(val_loss)\n",
        "            for name, m in metrics.items():\n",
        "                metrics_res[name].append(m.compute().cpu())\n",
        "        if (print_every > 0 and t % print_every == 0) or (\n",
        "                print_every >= 0 and t + 1 == epochs):\n",
        "            extras = [f\" {n} {v[-1]:<7f}\" if torch.isreal(v[-1])\n",
        "                      else f\" {n} {v[-1]}\"\n",
        "                      for n, v in metrics_res.items()]\n",
        "            print(f\"Epoch {t+1:<7d} train {train_loss:<7f} \"\n",
        "                  f\" validation {val_loss:<7f}\", \"\".join(extras))\n",
        "    if print_final:\n",
        "        print(\"\\n** Validation metrics after training **\\n\"\n",
        "              f\"Loss {val_losses[-1]:<7g}\")\n",
        "        for n, v in metrics_res.items():\n",
        "            if torch.isreal(v[-1]):\n",
        "                print(f\"{n} {v[-1]:<7g}\")\n",
        "            else:\n",
        "                print(f\"{n}:\")\n",
        "                print(v[-1])\n",
        "        print()\n",
        "    return train_losses, val_losses, metrics_res\n",
        "\n",
        "def plot_training(train_loss, val_loss, metrics_res={}):\n",
        "    \"Plot the training history\"\n",
        "    plt.figure()\n",
        "    plt.ylabel('Loss / Metric')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.plot(train_loss, label=\"Training loss\")\n",
        "    plt.plot(val_loss, label=\"Validation loss\")\n",
        "    for name, res in metrics_res.items():\n",
        "        if torch.isreal(res[0]):\n",
        "            plt.plot(res, label=name)\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "\n",
        "# Generate training data\n",
        "x_trn, d_trn = regr1(50, 2, 0, 0.0)\n",
        "\n",
        "# Standardization of inputs\n",
        "mu, std = standard(x_trn)\n",
        "x_trn = (x_trn - mu) / std\n",
        "\n",
        "# Define the network, cost function and training settings\n",
        "model_ex1 = Network(\n",
        "    inputs=1,            # number of input nodes\n",
        "    outputs=1,           # number of output nodes\n",
        "    nodes=[4],           # number of nodes in hidden layer\n",
        "    activation=nn.Tanh,  # activation function in hidden layer\n",
        "    out_activation=None  # activation function in output layer (if not linear)\n",
        "    ).to(device)         # move data to GPU or keep with CPU\n",
        "\n",
        "# Optimization parameters\n",
        "opt_method = torch.optim.SGD  # minimization method\n",
        "learning_rate = 0.05          # learning rate\n",
        "loss_fn = nn.MSELoss()        # loss function, MSE\n",
        "number_epochs = 4000\n",
        "minibatch_size = 50\n",
        "\n",
        "# Additional metrics to print\n",
        "metrics = {'MSE': torchmetrics.MeanSquaredError()}\n",
        "\n",
        "# Set up the optimizer\n",
        "optimizer = opt_method(model_ex1.parameters(), lr=learning_rate)\n",
        "\n",
        "# Print a summary of the model\n",
        "print(model_ex1)\n",
        "\n",
        "# Turn the training data into a dataset with Tensors on the GPU or CPU\n",
        "dset_trn = TensorDataset(torch.tensor(x_trn, device=device, dtype=dtype_torch),\n",
        "                         torch.tensor(d_trn, device=device, dtype=dtype_torch))\n",
        "\n",
        "# Create a batch loader for the training data\n",
        "dl_trn = DataLoader(dset_trn, batch_size=minibatch_size)\n",
        "\n",
        "# Train the network and print the progress\n",
        "train_loss, val_loss, metrics_res = train_loop(\n",
        "    model=model_ex1,\n",
        "    train_dataloader=dl_trn,\n",
        "    val_dataloader=dl_trn, # Test with the training data\n",
        "    loss_fn=loss_fn,\n",
        "    metrics=metrics,\n",
        "    optimizer=optimizer,\n",
        "    print_every=100,\n",
        "    epochs=number_epochs)\n",
        "\n",
        "# Plot the training history\n",
        "plot_training(train_loss, val_loss, metrics_res)\n",
        "\n",
        "# Predict output on the training data\n",
        "d_pred = model_ex1.predict(x_trn)\n",
        "\n",
        "# Plot the result\n",
        "plt.figure()\n",
        "plt.ylabel('Prediction / Target')\n",
        "plt.xlabel('Input')\n",
        "plt.scatter(x_trn, d_trn, label='Target')\n",
        "plt.scatter(x_trn, d_pred, label='Prediction')\n",
        "plt.title('Prediction vs Target')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {
        "height": "530px",
        "width": "356.167px"
      },
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}