{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "slideshow": {
          "slide_type": ""
        },
        "tags": []
      },
      "source": [
        "<h1 style=\"font-size:40px;\"><center>Exercise III:<br> Convolutional and Recurrent Neural Networks\n",
        "</center></h1>\n",
        "\n",
        "# Short summary\n",
        "In this exercise you will: \n",
        "\n",
        "* Train CNNs for a binary classification problem\n",
        "* Visualize how CNNs interprets the data\n",
        "* Train CNNs for two 3-class classification problem\n",
        "* Train a RNN on a time series prediction problem\n",
        "* Visualize RNN hidden node activities\n",
        "\n",
        "In this computer exercise we will look at network architectures that are designed to handle specific kinds of data: Convolutional Neural Networks for image processing and Recurrent Neural Networks for time series processing\n",
        "\n",
        "**Deadline for submitting the report: See Canvas assignment.**\n",
        "\n",
        "## The data\n",
        "Digits \"5\" and \"6\" from the MNIST database used for a binary classification problem.\n",
        "\n",
        "A dataset consisting of circles, rectangles or triangles, that can be read using the `loadImagesCRT` function.\n",
        "\n",
        "A dataset consisting of three different types of rectangles, squares, \"horizontal\" rectangles and \"vertical\" rectangles. This data can be read using the `loadImagesR3` function.\n",
        "\n",
        "A dataset consisting of pairs of times series. The input time series is a train of rectangle pulses, and the output is triangles, i.e. an up-ramp followed by a down-ramp. For more details see the cell *Ex4-1*. The task is to train a recurrent network that predicts the triangle time series from the pulse time series.\n",
        "\n",
        "\n",
        "## The exercises\n",
        "As with the previous computer exercises, all problems are found below.\n",
        "\n",
        "## The different \"cells\"\n",
        "This notebook contains several cells with python code, together with the markdown cells (like this one) with only text. Each of the cells with python code has a \"header\" markdown cell with information about the code. The table below provides a short overview of the code cells. \n",
        "\n",
        "| #  |  CellName | CellType | Comment |\n",
        "| :--- | :-------- | :-------- | :------- |\n",
        "| 1 | Init | Needed | Sets up the environment|\n",
        "| 2 | Data | Needed | Loading images for the CNN exercise |\n",
        "| 3 | PlotImg | Information  | View some of the images |\n",
        "| 4 | CNN Network | Needed | Defines the Network class for CNNs |\n",
        "| 5 | Stats | Needed | Show classification results and confusion matrix |\n",
        "| 6 | Metrics | Needed | Various metrics for model validation |\n",
        "| 7 | Training | Needed | Functions for training and testing the CNN model |\n",
        "| 8 | Visualization | Needed | Visualizes layers of a CNN |\n",
        "| 9 | RNN | Needed | Defines network and training for recurrent networks |\n",
        "| 10 | Ex1 | Exercise | For question 1-2 |\n",
        "| 11 | Ex2 | Exercise | For question 3 |\n",
        "| 12 | Ex3 | Exercise | For question 4-5 |\n",
        "| 13 | Ex4-1 | Exercise | For question 6-9 |\n",
        "| 14 | Ex4-2 | Exercise | For question 6-9 |\n",
        "| 15 | Ex4-3 | Exercise | For question 6-9 |\n",
        "\n",
        "\n",
        "In order for you to start with the exercise you need to run all cells with the CellType \"Needed\". The very first time you start with this exercise we suggest that you enter each of the needed cells, read the cell instruction and run the cell. It is important that you do this in the correct order, starting from the top and work you way down the cells. Later when you have started to work with the notebook it may be easier to use the command \"Run All\" found in the \"Cell\" dropdown menu.\n",
        "\n",
        "## Writing the report\n",
        "First the report should be written within this notebook. We have prepared the last cell in this notebook for you where you should write the report. The report should contain 4 parts:\n",
        "\n",
        "* Name.\n",
        "* Introduction: A **few** sentences where you give a small introduction of what you have done in this exercise.\n",
        "* Answers to questions: For each of the questions provide an answer. It can be short answers or longer ones depending on the nature of the questions, but try to be efficient in your writing.\n",
        "* Conclusion: Summarize your findings in a few sentences.\n",
        "\n",
        "It is important that you write the report in this last cell and **not** after each question! \n",
        "\n",
        "## Last but not least\n",
        "Have fun again!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "slideshow": {
          "slide_type": ""
        },
        "tags": []
      },
      "source": [
        "# CellName: Init (#1)\n",
        "**CellType: Needed**  \n",
        "**Cell instruction: Initializing the libraries**\n",
        "\n",
        "In the cell below, we import all the libraries that are needed for this exercises.\n",
        "\n",
        "Run the cell by entering into the cell and press \"CTRL Enter\".\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "device = 'cpu'\n",
        "# Uncomment this to use CUDA acceleration if available\n",
        "# device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
        "print(f\"PyTorch: Using {device} device\")\n",
        "# The floating point data type can be changed here\n",
        "dtype_torch = torch.float32\n",
        "\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch import nn, Tensor\n",
        "from collections import OrderedDict\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, log_loss, classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "slideshow": {
          "slide_type": ""
        },
        "tags": []
      },
      "source": [
        "# CellName: Data (#2)\n",
        "**CellType: Needed**  \n",
        "**Cell instruction: Function for getting images for the CNN exercises**\n",
        "\n",
        "This cell defines the functions that obtain the images needed for the CNN exercise. **Note**: Make sure the \"crt-trn/\" and \"crt-tst/\" folders are available in the same directory as this notebook file when you actually call these functions. Otherwise, the files files are not found.\n",
        "\n",
        "Run the cell by entering into the cell and press \"CTRL Enter\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "basedir = \"./\"\n",
        "\n",
        "def loadImagesCRT():\n",
        "    xtrain, ytrain, xval, yval = np.load(basedir + \"crt.npy\", allow_pickle=True)\n",
        "    width, height = xtrain.shape[2:]\n",
        "    return xtrain, ytrain, xval, yval, width, height\n",
        "\n",
        "def loadImagesR3():\n",
        "    xtrain, ytrain, xval, yval = np.load(basedir + \"r3.npy\", allow_pickle=True)\n",
        "    width, height = xtrain.shape[2:]\n",
        "    return xtrain, ytrain, xval, yval, width, height\n",
        "\n",
        "def loadMNIST56():\n",
        "    xtrain, ytrain, xval, yval = np.load(basedir + \"mnist56t.npy\", allow_pickle=True)\n",
        "    width, height = xtrain.shape[2:]\n",
        "    return xtrain, ytrain, xval, yval, width, height"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "slideshow": {
          "slide_type": ""
        },
        "tags": []
      },
      "source": [
        "# CellName: PlotImg (#3)\n",
        "**CellType: Information**  \n",
        "**Cell instruction: Show some of the images**\n",
        "\n",
        "Here we look at the first ten pictures in the training set, and their respective targets. You can select the dataset to look at by uncomment the correct line.\n",
        "\n",
        "Run the cell by entering into the cell and press \"CTRL Enter\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "xTrn, dTrn, xVal, dVal, width, height = loadMNIST56()\n",
        "# xTrn, dTrn, xVal, dVal, width, height = loadImagesCRT()\n",
        "# xTrn, dTrn, xVal, dVal, width, height = loadImagesR3()\n",
        "\n",
        "rndSel = np.random.randint(len(xTrn), size=10)\n",
        "plt.figure(1, figsize=(14,6))\n",
        "plt.imshow(xTrn[rndSel,0,:,:].swapaxes(0,1).reshape(width, 10*height), cmap=\"gray\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "slideshow": {
          "slide_type": ""
        },
        "tags": []
      },
      "source": [
        "# CellName: CNN network (#4)\n",
        "**CellType: Needed**  \n",
        "**Cell instruction: Defining the ANN model**\n",
        "\n",
        "This cell defines a generic ANN model. In the two earlier computer exercises, it was sufficient to specify the number of nodes in each layer. Now you'll have to specify the layers in more detail through an `OrderedDict` of `Module`s from `nn`. Examples of modules are:\n",
        "* `nn.Linear` – fully connected layer\n",
        "* `nn.Conv2d` – 2D convolutional layer\n",
        "* `nn.MaxPool2d` – 2D maxpooling layer\n",
        "* `nn.ReLU` and `nn.Softmax` – activation layers\n",
        "* `nn.Dropout` – dropout layer\n",
        "\n",
        "Many of these require settings such as the input and output dimensions, kernel size, stride or what dimension of the input to operate on.\n",
        "\n",
        "In the exercise sections you'll see examples of how to specify layers in the `OrderedDict` that will be passed to `Network`. Note that you actually create the layers already there, and the `Network` then uses an `nn.Sequential` to connect them. When we train the network, Pytorch manages the dependencies between the network weights/biases and the output for us.\n",
        "\n",
        "* seqstack: the `OrderedDict` explained above.\n",
        "* l2regularization: L2 regularization strength for `Linear` layers.\n",
        "\n",
        "Run the cell by entering into the cell and press \"CTRL Enter\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Network(nn.Module):\n",
        "    \"A generic network with optional L2 regularization\"\n",
        "    def __init__(self, seqstack : OrderedDict, *, l2regularization=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            seqstack (OrderedDict): The layers of the network.\n",
        "            l2regularization (float or dict, optional): Regularization strength for all linear layers or for named layers.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.layer_stack = nn.Sequential(seqstack)\n",
        "        if isinstance(l2regularization, dict):\n",
        "            self.l2regularization = [(lambd, seqstack[name]) for name, lambd\n",
        "                                     in l2regularization.items()]\n",
        "        elif l2regularization:\n",
        "            self.l2regularization = [\n",
        "                (l2regularization, layer) for layer in seqstack.values()\n",
        "                if isinstance(layer, nn.Linear)]\n",
        "        else:\n",
        "            self.l2regularization = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"Apply the network stack on some input\"\n",
        "        return self.layer_stack(x)\n",
        "\n",
        "    def regularization_loss(self):\n",
        "        \"Compute the total regularization cost\"\n",
        "        if self.l2regularization is None:\n",
        "            return 0\n",
        "        loss = 0\n",
        "        for lambd, layer in self.l2regularization:\n",
        "            loss = loss + lambd * torch.norm(layer.weight, p=2)\n",
        "        return loss\n",
        "\n",
        "    def get_layer(self, name : str):\n",
        "        \"Get layer by name\"\n",
        "        module_dict = dict(self.layer_stack.named_modules())\n",
        "        return module_dict[name]\n",
        "\n",
        "    def predict(self, input_data):\n",
        "        \"\"\"\n",
        "        Apply the network on a set of input data.\n",
        "\n",
        "        Args:\n",
        "            input_data (np.ndarray or Tensor): Input data\n",
        "\n",
        "        Returns:\n",
        "            pred (np.ndarray or Tensor): Predicted output.\n",
        "        \"\"\"\n",
        "        self.eval()\n",
        "        if isinstance(input_data, np.ndarray):\n",
        "            inp = torch.tensor(input_data, dtype=dtype_torch, device=device)\n",
        "            with torch.no_grad():\n",
        "                pred = self(inp)\n",
        "            return pred.cpu().detach().numpy()\n",
        "        with torch.no_grad():\n",
        "            return self(input_data.to(device))\n",
        "\n",
        "    def __str__(self):\n",
        "        s = super().__str__()\n",
        "        ps = [\"Named parameters:\"] + [\n",
        "            f\"{name}: {param.numel()}\" for name, param in\n",
        "             self.layer_stack.named_parameters() if param.requires_grad]\n",
        "        totp = sum(p.numel() for p in self.layer_stack.parameters() if p.requires_grad)\n",
        "        return s + f\"\\nTrainable parameters: {totp}\\n\" + \"\\n  \".join(ps) + \"\\n\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "slideshow": {
          "slide_type": ""
        },
        "tags": []
      },
      "source": [
        "# CellName: Stats (#5)\n",
        "**CellType: Needed**  \n",
        "**Cell instruction: Show classification results**\n",
        "\n",
        "This cell just defines functions that we can call to compute some performance measures for classification problems.\n",
        "\n",
        "Run the cell by entering into the cell and press \"CTRL Enter\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def stats_classification(model : Network, dset : TensorDataset,\n",
        "                         *, label : str, loss_fn = None):\n",
        "    \"\"\"\n",
        "    Print classification statistics.\n",
        "\n",
        "    Args:\n",
        "        model (Network): The model.\n",
        "        dset (TensorDataset): Input and target data.\n",
        "        label (str): Training, test etc.\n",
        "        loss (optional): Loss function.\n",
        "\n",
        "    Returns:\n",
        "        None.\n",
        "    \"\"\"\n",
        "    pred = model.predict(dset.tensors[0])\n",
        "    targ = dset.tensors[1]\n",
        "    if loss_fn is not None:\n",
        "        loss = loss_fn(pred, targ)\n",
        "\n",
        "    if targ.shape[1] == 1:\n",
        "        # Binary\n",
        "        pred = pred >= .5\n",
        "        targ = targ >= .5\n",
        "        nof_p, tp, tn = [k.sum() for k in [targ, pred[targ], ~pred[~targ]]]\n",
        "        stats = {'Accuracy': (tp + tn) / len(targ),\n",
        "                 'Sensitivity': tp / nof_p,\n",
        "                 'Specificity': tn / (len(targ) - nof_p)}\n",
        "    else:\n",
        "        # One-hot\n",
        "        pred = pred.argmax(axis=1)\n",
        "        targ = targ.argmax(axis=1)\n",
        "        stats = {'Accuracy': (pred == targ).sum() / len(targ)}\n",
        "\n",
        "    if loss_fn is not None:\n",
        "        stats['Loss'] = loss\n",
        "\n",
        "    print(f\"*** STATISTICS for {label} Data ***\")\n",
        "    for l, v in stats.items():\n",
        "        print(f'{l:15} {v:.4f}')\n",
        "    print()\n",
        "\n",
        "def plot_confusion_matrix(cm, target_names, title='Confusion matrix',\n",
        "                          cmap=None, normalize=True):\n",
        "    \"Plot a confusion matrix\"\n",
        "\n",
        "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
        "    misclass = 1 - accuracy\n",
        "\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        else:\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label\\n'\n",
        "               f'accuracy={accuracy:0.4f}; misclass={misclass:0.4f}')\n",
        "    plt.show()\n",
        "\n",
        "def make_cm_plot(model, inp, trg, label='Test data'):\n",
        "    \"\"\"\n",
        "    Compute and plot the confusion matrix\n",
        "    \"\"\"\n",
        "    print(f'*** Result for {label} ***')\n",
        "\n",
        "    num_classes = trg.shape[1]\n",
        "    y = model.predict(inp)\n",
        "\n",
        "    print(f'log_loss:   {log_loss(trg, y):.4f}')\n",
        "    d_class = trg.argmax(axis=1)\n",
        "    y_class = y.argmax(axis=1)\n",
        "    acc = (y_class==d_class).mean()\n",
        "    print(f'accuracy:   {acc:.4f}\\n')\n",
        "\n",
        "    class_names = [f'class {i+1}' for i in range(num_classes)]\n",
        "    print(classification_report(d_class, y_class, target_names=class_names))\n",
        "\n",
        "    confuTst = confusion_matrix(d_class, y_class)\n",
        "    plot_confusion_matrix(cm           = confuTst,\n",
        "                          normalize    = False,\n",
        "                          target_names = class_names,\n",
        "                          title        = f\"Confusion Matrix, {label}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CellName: Metrics (#6)\n",
        "**CellType: Needed**  \n",
        "**Cell Instruction: Functions for evaluating various metrics during training**\n",
        "\n",
        "Run the cell by entering into the cell and press \"CTRL Enter\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SimpleMetric():\n",
        "    \"\"\" Base class for any metric that keeps a numerator and denominator,\n",
        "    designed as a simple drop-in replacement for torchmetrics.\n",
        "    \"\"\"\n",
        "    def __init__(self, v=None):\n",
        "        if v is not None:\n",
        "            self.v = v\n",
        "        else:\n",
        "            self.v = torch.zeros(2)\n",
        "\n",
        "    def reset(self):\n",
        "        self.v = torch.zeros_like(self.v)\n",
        "\n",
        "    def to(self, device):\n",
        "        v = self.v.to(device)\n",
        "        return self if v is self.v else type(self)(v)\n",
        "\n",
        "    def compute(self):\n",
        "        return self.v[0] / self.v[1]\n",
        "\n",
        "class MSEMetric(SimpleMetric):\n",
        "    \"\"\" Mean square error metric.\n",
        "    \"\"\"\n",
        "    def update(self, pred, y):\n",
        "        self.v[0] += ((pred - y)**2).sum()\n",
        "        self.v[1] += y.numel()\n",
        "\n",
        "class BinaryAccuracyMetric(SimpleMetric):\n",
        "    \"\"\" Binary accuracy metric. Predictions will be thresholded at 0.5.\n",
        "    \"\"\"\n",
        "    def update(self, pred, y):\n",
        "        if pred.is_floating_point():\n",
        "            pred = pred >= .5\n",
        "        self.v[0] += (pred == y).sum()\n",
        "        self.v[1] += y.numel()\n",
        "\n",
        "class ClassificationAccuracyMetric(SimpleMetric):\n",
        "    \"\"\" One-hot classification accuracy metric.\n",
        "    \"\"\"\n",
        "    def update(self, pred, y):\n",
        "        y = y.argmax(-1)\n",
        "        pred = pred.argmax(-1)\n",
        "        self.v[0] += (pred == y).sum()\n",
        "        self.v[1] += y.numel()\n",
        "\n",
        "class ClassificationErrorMetric():\n",
        "    \"\"\" One-hot classification metric base class.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes, v=None):\n",
        "        self.num_classes = num_classes\n",
        "        if v is not None:\n",
        "            self.v = v\n",
        "        else:\n",
        "            self.v = torch.zeros(self.num_classes, self.num_classes,\n",
        "                                 dtype=torch.int64)\n",
        "\n",
        "    def reset(self):\n",
        "        self.v = torch.zeros_like(self.v)\n",
        "\n",
        "    def to(self, device):\n",
        "        v = self.v.to(device)\n",
        "        return self if v is self.v else type(self)(self.num_classes, v)\n",
        "\n",
        "    def update(self, pred, y):\n",
        "        y = y.argmax(-1)\n",
        "        pred = pred.argmax(-1)\n",
        "        self.v.index_put_((y, pred),\n",
        "            torch.ones_like(y, dtype=self.v.dtype),\n",
        "            accumulate=True)\n",
        "\n",
        "class ClassificationF1Metric(ClassificationErrorMetric):\n",
        "    \"\"\" One-hot classification macro F1 score metric.\n",
        "    \"\"\"\n",
        "    def compute(self):\n",
        "        tp = torch.diag(self.v)\n",
        "        f1 = 2 * tp / (self.v.sum(0) + self.v.sum(1))\n",
        "        return f1.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CellName: Training (#7)\n",
        "**CellType: Needed**  \n",
        "**Cell Instruction: Functions for training and testing the model**\n",
        "\n",
        "Like in the previous exercises, this cell defines functions for training the model for a single epoch (`train_epoch`),\n",
        "evaluating the performance (`test`) and training and testing a previously defined `Network` model over many epochs (`train_loop`).\n",
        "\n",
        "* loss_fn: The error function used during training. There are three common ones\n",
        "    * `nn.MSELoss` (mean squared error)\n",
        "    * `nn.BCELoss` (binary cross entropy)\n",
        "    * `nn.CrossEntropyLoss` (categorical cross entropy)<p>\n",
        "\n",
        "Run the cell by entering into the cell and press \"CTRL Enter\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test(*, model : Network, dataloader : DataLoader, loss_fn, metrics=[]):\n",
        "    \"\"\"\n",
        "    Test a model on a set of data.\n",
        "\n",
        "    Args:\n",
        "        model (Network): The network.\n",
        "        dataloader (DataLoader): DataLoader with data to test.\n",
        "        loss_fn (Loss): Loss function, e.g. nn.MSELoss.\n",
        "        metrics (iterable): Additional metrics to update.\n",
        "\n",
        "    Returns:\n",
        "        loss (float): Mean error over all batches.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    loss = 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            loss += loss_fn(pred, y).item() * len(X)\n",
        "            for m in metrics:\n",
        "                m.update(pred, y)\n",
        "    return loss / len(dataloader.dataset)\n",
        "\n",
        "\n",
        "def train_loop(*, model : Network, train_dataloader : DataLoader,\n",
        "               val_dataloader : DataLoader = None, loss_fn,\n",
        "               optimizer : torch.optim.Optimizer, epochs : int,\n",
        "               print_every:int = 100, metrics=None, print_final=True):\n",
        "    \"\"\"\n",
        "    Train and optionally test a model.\n",
        "\n",
        "    Args:\n",
        "        model (Network): The network.\n",
        "        train_dataloader (DataLoader): Training data.\n",
        "        val_dataloader (DataLoader, optional): Validation data.\n",
        "        loss_fn (Loss): Loss function, e.g. nn.MSELoss.\n",
        "        optimizer (Optimizer): An optimizer from torch.optim.\n",
        "        epochs (int): Number of epochs to train for.\n",
        "        print_every (int, optional): Print loss every so many epochs. Defaults to 100.\n",
        "        metrics (dict(name: metric), optional): Record/print these additional metrics.\n",
        "        print_final(bool, optional): Print final metrics. Defaults to True.\n",
        "\n",
        "    Returns:\n",
        "        train_losses (list(float)): Training loss during each epoch.\n",
        "        val_losses (list(float)): Validation loss after each epoch.\n",
        "        metrics_res (dict(name: list(float))): Values of metrics after each epoch.\n",
        "    \"\"\"\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_loss = np.nan\n",
        "\n",
        "    # Move metrics to CPU/GPU and prepare for their output\n",
        "    metrics = {name: m.to(device) for name, m in (metrics or {}).items()}\n",
        "    metrics_res = {name+\"-t\": [] for name in metrics.keys()}\n",
        "    metrics_res.update({name+\"-v\": [] for name in metrics.keys()})\n",
        "\n",
        "    for t in range(epochs):\n",
        "        for m in metrics.values():\n",
        "            m.reset()\n",
        "        train_loss = train_epoch(model=model, dataloader=train_dataloader,\n",
        "                           loss_fn=loss_fn, optimizer=optimizer,\n",
        "                           metrics=metrics.values())\n",
        "        train_losses.append(train_loss)\n",
        "        for name, m in metrics.items():\n",
        "            metrics_res[name+\"-t\"].append(m.compute().cpu())\n",
        "\n",
        "        if val_dataloader is not None:\n",
        "            for m in metrics.values():\n",
        "                m.reset()\n",
        "            val_loss = test(dataloader=val_dataloader, model=model,\n",
        "                            loss_fn=loss_fn, metrics=metrics.values())\n",
        "            val_losses.append(val_loss)\n",
        "            for name, m in metrics.items():\n",
        "                metrics_res[name+\"-v\"].append(m.compute().cpu())\n",
        "\n",
        "        if (print_every > 0 and t % print_every == 0) or (\n",
        "                print_every >= 0 and t + 1 == epochs):\n",
        "            extras = [f\" {n} {v[-1]:<7f}\" if torch.isreal(v[-1])\n",
        "                      else f\" {n} {v[-1]}\"\n",
        "                      for n, v in metrics_res.items()]\n",
        "            print(f\"Epoch {t+1:<7d} train {train_loss:<7f} \"\n",
        "                  f\" validation {val_loss:<7f}\", \"\".join(extras))\n",
        "    if print_final:\n",
        "        print(\"\\n** Validation metrics after training **\\n\"\n",
        "              f\"Loss {val_losses[-1]:<7g}\")\n",
        "        for n, v in metrics_res.items():\n",
        "            if torch.isreal(v[-1]):\n",
        "                print(f\"{n} {v[-1]:<7g}\")\n",
        "            else:\n",
        "                print(f\"{n}:\")\n",
        "                print(v[-1])\n",
        "        print()\n",
        "    return train_losses, val_losses, metrics_res\n",
        "\n",
        "def train_epoch(*, model : Network, dataloader : DataLoader,\n",
        "                loss_fn, optimizer : torch.optim.Optimizer, metrics=[]):\n",
        "    \"\"\"\n",
        "    Train a model for a single epoch.\n",
        "\n",
        "    Args:\n",
        "        model (Network): The network.\n",
        "        dataloader (DataLoader): Batch DataLoader with training data.\n",
        "        loss_fn (Loss): Loss function, e.g. nn.MSELoss.\n",
        "        optimizer (Optimizer): The optimizer used to update the network.\n",
        "        metrics (iterable): Additional metrics to update.\n",
        "\n",
        "    Returns:\n",
        "        train_loss (float): Training error over all batches.\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for X, y in dataloader:\n",
        "        X, y = X.to(device), y.to(device)   # Move data to GPU if necessary\n",
        "        optimizer.zero_grad()   # Reset the gradients\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "        train_loss += loss.item() * len(X)\n",
        "        loss = loss + model.regularization_loss()\n",
        "        for m in metrics:\n",
        "            m.update(pred.detach(), y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    return train_loss / len(dataloader.dataset)\n",
        "\n",
        "def plot_training(train_loss, val_loss, metrics_res={}):\n",
        "    \"Plot the training history\"\n",
        "    plt.figure()\n",
        "    plt.ylabel('Loss / Metric')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.plot(train_loss, label=\"Training loss\")\n",
        "    plt.plot(val_loss, label=\"Validation loss\")\n",
        "    for name, res in metrics_res.items():\n",
        "        if torch.isreal(res[0]):\n",
        "            plt.plot(res, label=name)\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "slideshow": {
          "slide_type": ""
        },
        "tags": []
      },
      "source": [
        "# CellName: Visualization (#8)\n",
        "**CellType: Needed**  \n",
        "**Cell instruction: Function that can visualize the different layers of a CNN**\n",
        "\n",
        "This cell is feeding an image through a CNN and stores the intemediate values. It plots the different layers (filtered images) either before or after maxpooling.\n",
        "\n",
        "Run the cell by entering into the cell and press \"CTRL Enter\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def layerVisualization(model : Network, layernames : list,\n",
        "                       indata, target, idx=10):\n",
        "    # Catch the output of the layer\n",
        "    ind = indata[[idx]]\n",
        "    plot_data = [ind]\n",
        "    def hook(model, input, output):\n",
        "        plot_data.append(output.detach().numpy())\n",
        "\n",
        "    handles = []\n",
        "    for name in layernames:\n",
        "        layer = model.get_layer(name)\n",
        "        handles.append(layer.register_forward_hook(hook))\n",
        "\n",
        "    pred = model.predict(ind)\n",
        "    for handle in handles:\n",
        "        handle.remove()\n",
        "\n",
        "    print('Prediction: ', pred)\n",
        "    print('Target    : ', target[idx])\n",
        "\n",
        "    plt.figure(tight_layout=True)\n",
        "    # plt.figure(figsize=(18,12), tight_layout=True)\n",
        "    for k, s in enumerate(plot_data):\n",
        "        plt.subplot(len(plot_data), 1, k+1)\n",
        "        pics = s[0]\n",
        "        # pics = np.rollaxis(pics,2,0)\n",
        "        rows = 2 if pics.shape[0] > 8 else 1\n",
        "        cols = pics.shape[0]//rows\n",
        "        pad = pics.shape[0]-rows*cols\n",
        "        if pad > 0:\n",
        "            padding = np.zeros_like(pics, shape=(rows-pad,)+pics.shape[1:])\n",
        "            pics = np.concatenate([pics, padding])\n",
        "            cols = cols + 1\n",
        "        imgshape = pics.shape[1:]\n",
        "        pics = pics.reshape((rows,cols)+imgshape)\n",
        "        pics = pics.swapaxes(1,2)\n",
        "        pics = pics.reshape((pics.shape[0]*pics.shape[1], pics.shape[2]*pics.shape[3]))\n",
        "        extent = (0, cols*imgshape[0], 0,rows*imgshape[1])\n",
        "        plt.imshow(pics,cmap='gray',extent=extent)\n",
        "        for r in range(1,rows):\n",
        "            plt.plot([0,cols*imgshape[0]], [r*imgshape[1], r*imgshape[1]], color='r', linestyle='-', linewidth=1)\n",
        "        for c in range(1,cols):\n",
        "            plt.plot([c*imgshape[0], c*imgshape[0]], [0,rows*imgshape[1]], color='r', linestyle='-', linewidth=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CellName: RNN (#9)\n",
        "**CellType: Needed**  \n",
        "**Cell instruction: Class defining recurrent networks and function for training them**\n",
        "\n",
        "This cell defines a generic recurrent model, with a class `StatefulNetwork` which can hold several recurrent layers and a memory of their state.\n",
        "\n",
        "The options are more limited here than in the previous exercises: You can select the type of network nodes and the number of hidden layers and nodes. For the simple RNNs you can also choose between tanh and relu activation functions (`nonlinearity`).\n",
        "\n",
        "The `train_TBPTT` function performs *truncated back-propagation through time* on a network. The time series data is assumed to consist of a single quantity (the pulse level) over a constant number of timepoints. Data are divided into batches by `DataLoader` and further divided into time segments of length `truncationlen`.\n",
        "\n",
        "Arguments to this function are:\n",
        " * `epochs` the number of epochs\n",
        " * `truncationlen` the number of time points between weight updates *and* the depth of back-propagatation through time.\n",
        "\n",
        "Run the cell by entering into the cell and press \"CTRL Enter\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class StatefulNetwork(nn.Module):\n",
        "    \"A recurrent network for BPTT\"\n",
        "    def __init__(self, nettype, nodes=[10], **kwargs):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            nettype (type): Network type, e.g. nn.RNN, nn.GRU or nn.LSTM.\n",
        "            nodes (list of int): The number of nodes in each hidden layer.\n",
        "            kwargs: nettype-specific arguments. For RNN there is one option:\n",
        "                nonlinearity can be 'relu' or 'tanh' (default)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.rnns = nn.ModuleList()\n",
        "        prevn = 1\n",
        "        for n in nodes:\n",
        "            self.rnns.append(\n",
        "                nettype(prevn, hidden_size=n, batch_first=True,\n",
        "                        device=device, dtype=dtype_torch, **kwargs))\n",
        "            prevn = n\n",
        "        self.fc = nn.Linear(prevn, 1)\n",
        "        self.reset_hidden_state()\n",
        "\n",
        "    def reset_hidden_state(self):\n",
        "        \"Clear hidden state memory\"\n",
        "        self.hidden = [None] * len(self.rnns)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"Apply the network to a batch of data.\"\n",
        "        for i, rnn in enumerate(self.rnns):\n",
        "            x, hx = rnn(x, self.hidden[i])\n",
        "            # Detach hidden states to stop backpropagation\n",
        "            if isinstance(hx, tuple): # For LSTM (hidden state, cell state)\n",
        "                self.hidden[i] = tuple(t.detach() for t in hx)\n",
        "            else:\n",
        "                self.hidden[i] = hx.detach()\n",
        "        return self.fc(x)\n",
        "\n",
        "    def predict(self, input_data):\n",
        "        \"\"\"\n",
        "        Apply the network on a set of input data.\n",
        "        \"\"\"\n",
        "        self.eval()\n",
        "        self.reset_hidden_state()\n",
        "        inp = torch.tensor(input_data, dtype=dtype_torch, device=device)\n",
        "        with torch.no_grad():\n",
        "            pred = self(inp)\n",
        "        return pred.cpu().numpy()\n",
        "\n",
        "    def __str__(self):\n",
        "        s = super().__str__()\n",
        "        totp = sum(p.numel() for r in self.rnns for p in r.parameters() if p.requires_grad)\n",
        "        totp = totp + sum(p.numel() for p in self.fc.parameters() if p.requires_grad)\n",
        "        return s + f\"\\nTrainable parameters: {totp}\\n\"\n",
        "\n",
        "\n",
        "def train_TBPTT(model : StatefulNetwork, epochs : int, truncationlen : int,\n",
        "               optimizer : torch.optim.Optimizer, train_dataloader : DataLoader,\n",
        "               val_dataloader : DataLoader, loss_fn=nn.MSELoss(), print_every=1):\n",
        "    \"\"\"\n",
        "    Train a recurrent network with truncated backpropagation through time.\n",
        "    The data should be a 3D tensor of shape (sample, time, 1)\n",
        "\n",
        "    Args:\n",
        "        model (StatefulNetwork): The network model to train\n",
        "        epochs (int): Number of epochs.\n",
        "        truncationlen (int): The time segment size in TBPTT.\n",
        "        optimizer (Optimizer): Torch optimizer, e.g. Adam.\n",
        "        train_dataloader (DataLoader): Training data loader.\n",
        "        val_dataloader (DataLoader): Validation data loader.\n",
        "        loss_fn (optional): Loss function. Defaults to nn.MSELoss().\n",
        "        print_every (int, optional): Print loss every n lines. Defaults to 1.\n",
        "\n",
        "    Returns:\n",
        "        loss_t (list of double): Training loss.\n",
        "        loss_v (list of double): Validation loss\n",
        "    \"\"\"\n",
        "\n",
        "    if print_every > 0:\n",
        "        print(\"Epoch   Train-loss     Val-loss\")\n",
        "    loss_t = []\n",
        "    loss_v = []\n",
        "    for ne in range(epochs):\n",
        "        loss = 0\n",
        "        for X, Y in train_dataloader:\n",
        "            X, Y = X.to(device), Y.to(device)   # Move data to GPU if necessary\n",
        "            bloss = 0\n",
        "            optimizer.zero_grad()   # Reset the gradients\n",
        "            numt = X.shape[1]\n",
        "            model.reset_hidden_state()\n",
        "            for t in range(0, numt, truncationlen):\n",
        "                output = model(X[:, t:t+truncationlen])\n",
        "                target = Y[:, t:t+truncationlen]\n",
        "                tbloss = loss_fn(output, target)\n",
        "                tbloss.backward()\n",
        "                optimizer.step()\n",
        "                bloss = bloss + tbloss.item() * target.shape[1]\n",
        "            loss = loss + bloss / numt * len(X)\n",
        "        loss_t.append(loss / len(train_dataloader.dataset))\n",
        "\n",
        "        loss = 0\n",
        "        with torch.no_grad():\n",
        "            for X, Y in val_dataloader:\n",
        "                X, Y = X.to(device), Y.to(device)   # Move data to GPU if necessary\n",
        "                bloss = 0\n",
        "                numt = X.shape[1]\n",
        "                model.reset_hidden_state()\n",
        "                for t in range(0, numt, truncationlen):\n",
        "                    output = model(X[:, t:t+truncationlen])\n",
        "                    target = Y[:, t:t+truncationlen]\n",
        "                    bloss = bloss + loss_fn(output, target).item() * target.shape[1]\n",
        "                loss = loss + bloss / numt * len(X)\n",
        "            loss_v.append(loss / len(val_dataloader.dataset))\n",
        "\n",
        "        if print_every > 0 and (ne % print_every == 0 or ne == epochs - 1):\n",
        "            print(f\"{ne:5d}  {loss_t[-1]:11.6f}  {loss_v[-1]:11.6f}\")\n",
        "    return loss_t, loss_v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "slideshow": {
          "slide_type": ""
        },
        "tags": []
      },
      "source": [
        "# CellName: Ex1 (#10)\n",
        "**CellType: Exercise**  \n",
        "**Cell instruction: Instructions for question 1-2**\n",
        "\n",
        "## CNN for image classification\n",
        "\n",
        "In this first exercise you are going to train a CNN that can separate between numbers \"5\" and \"6\" from the mnist dataset (mnist56 dataset). We are going to use 2000 training images and 1850 validation images. To start with we have a proposed CNN that can solve this problem. It consists of the following:\n",
        "* First convolutional layer consisting of 4 kernels of size 3x3, with ReLU activation\n",
        "* Maxpooling of size 2x2\n",
        "* Second convolutional layer of 4 kernels of size 3x3, with ReLU activation\n",
        "* Maxpooling of size 2x2\n",
        "* Special layer `Flatten`, just transforms the all of the max pooled filter outputs to a linear vector of outputs\n",
        "* `Linear` layer, meaning a fully connected MLP layer, to 10 hidden nodes, again ReLU activation\n",
        "* Final `Linear` output layer consisting of one single output node with sigmoid activation function because we have a binary classification problem.\n",
        "\n",
        "The default is to use *stride* = 1 and no *padding*. \n",
        "\n",
        "### Question 1\n",
        "Make sure you understand the definition of the CNN model in the cell below and train it. **What is your validation set performance in terms of the accuracy?**\n",
        "\n",
        "### Question 2\n",
        "This image classification problem should be relatively easy since a \"5\" has some distinct differences from a \"6\". Experiment with the architecture of the CNN model and try to make it smaller (in terms of the number of trainable parameters), but with the same almost perfect validation accuracy (>98%). **How many parameters do you have in your trimmed model? What is your architecture?**\n",
        "\n",
        "**Hint:** There is of course very many ways you can make a smaller architecture. You do not need to test all of them!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the dataset, MNIST-56\n",
        "x_trn, d_trn, x_val, d_val, width, height = loadMNIST56()\n",
        "\n",
        "# Container for CNN layers that will be used to construct the Network\n",
        "layers = OrderedDict()\n",
        "\n",
        "# First convolutional layer\n",
        "layers[\"conv1\"] = nn.Conv2d(in_channels=1, out_channels=4,\n",
        "                            kernel_size=(3, 3))\n",
        "layers[\"act1\"] = nn.ReLU()\n",
        "layers[\"mp1\"] = nn.MaxPool2d((2, 2))\n",
        "\n",
        "# Second convolutional layer\n",
        "layers[\"conv2\"] = nn.Conv2d(4, 4, 3) # in_channels, out_channels, kernel size\n",
        "layers[\"act2\"] = nn.ReLU()\n",
        "layers[\"mp2\"] = nn.MaxPool2d((2, 2))\n",
        "\n",
        "# Fully connected MLP layers.\n",
        "# Use one input image to compute the number of nodes after convolution layers.\n",
        "n_features = nn.Sequential(layers)(Tensor(x_trn[0])).numel()\n",
        "layers[\"flat\"] = nn.Flatten()\n",
        "layers[\"mlp\"] = nn.Linear(n_features, 10)\n",
        "layers[\"amlp\"] = nn.ReLU()\n",
        "# Output layer\n",
        "layers[\"out\"] = nn.Linear(10, 1)\n",
        "layers[\"aout\"] = nn.Sigmoid()\n",
        "\n",
        "model_ex1 = Network(layers, l2regularization=0).to(device)\n",
        "\n",
        "# Hyperparameters\n",
        "opt_method = torch.optim.Adam   # minimization method\n",
        "learning_rate = 0.005           # learning rate\n",
        "loss_fn = nn.BCELoss()          # loss function, binary cross entropy\n",
        "number_epochs = 30\n",
        "minibatch_size = 64\n",
        "\n",
        "# Additional metrics to print {name: metric}\n",
        "metrics = {'accuracy': BinaryAccuracyMetric()}\n",
        "\n",
        "# Print a summary of the model\n",
        "print(model_ex1)\n",
        "\n",
        "# Set up the optimizer\n",
        "optimizer = opt_method(model_ex1.parameters(), lr=learning_rate)\n",
        "\n",
        "# Create datasets and batch loaders for the training and test data on the GPU or CPU\n",
        "dset_trn = TensorDataset(torch.tensor(x_trn, device=device, dtype=dtype_torch),\n",
        "                         torch.tensor(d_trn, device=device, dtype=dtype_torch))\n",
        "dl_trn = DataLoader(dset_trn, batch_size=minibatch_size, shuffle=True)\n",
        "\n",
        "dset_val = TensorDataset(torch.tensor(x_val, device=device, dtype=dtype_torch),\n",
        "                         torch.tensor(d_val, device=device, dtype=dtype_torch))\n",
        "dl_val = DataLoader(dset_val)\n",
        "\n",
        "\n",
        "# Train the network and print the progress\n",
        "train_loss, val_loss, metrics_res = train_loop(\n",
        "    model=model_ex1,\n",
        "    train_dataloader=dl_trn,\n",
        "    val_dataloader=dl_val,\n",
        "    loss_fn=loss_fn,\n",
        "    metrics=metrics,\n",
        "    optimizer=optimizer,\n",
        "    print_every=5,\n",
        "    epochs=number_epochs)\n",
        "\n",
        "# Plot the training history\n",
        "plot_training(train_loss, val_loss, metrics_res)\n",
        "\n",
        "# Call the stats function to print out statistics for binary classification problems\n",
        "stats_classification(model_ex1, dset_trn, loss_fn=loss_fn, label=\"Training\")\n",
        "stats_classification(model_ex1, dset_val, loss_fn=loss_fn, label=\"Validation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "slideshow": {
          "slide_type": ""
        },
        "tags": []
      },
      "source": [
        "# CellName: Ex2 (#11)\n",
        "**CellType: Exercise**  \n",
        "**Cell instruction: Instructions for question 3**\n",
        "\n",
        "You are now going to take a look into the CNN model. There are many attempts to visualize how the CNN model is making classifications. We will here just look at the different layer outputs given an input image. The function `layerVisualization`, found in cell #5 does the following:\n",
        "* Use one selected image from the supplied dataset.\n",
        "* Find some named layers and temporarily attach a \"hook\" to them to copy their output.\n",
        "* Make a forward pass through the CNN, remembering intermediate values for the named layers.\n",
        "* Plot all of the \"filters\" (channels) for each of the layers.\n",
        "* Through the selection of layers, you can e.g. select to plot before or after MaxPooling.\n",
        "\n",
        "You pass the model that you want to visualize to the `layerVisualization` function. If you do not change the variable names in cell Ex1, it should be `model_ex1`.\n",
        "\n",
        "## Question 3\n",
        "Train a CNN for the \"5\" vs \"6\" problem! As a suggestion use the following CNN (where \"dense\" denotes a fully connected layer, i.e. Linear+activation):\n",
        "\n",
        "***3x(3x3 kernel) - maxpool - 3x(3x3 kernel) - maxpool - (flatten) - dense(5) - dense(1)***\n",
        "\n",
        "Make sure that your trained model gives good validation results (i.e. > 95% accuracy). Having such a model, you can run the cell below. There are two parameters you need to specify, `idx` and `layers_vis`. As you can see, `layers_vis` is a list of named layers to visualize; you can specify `\"act1\"` etc. to plot the filters before maxpooling, or `\"mp1\"` etc. to show the result after maxpooling. The image to show is selected by the index `idx`. As an example, the following values represent,\n",
        "* idx=1 number \"6\"\n",
        "* idx=2 number \"5\"\n",
        "* idx=3 another number \"6\"\n",
        "* idx=5 another number \"5\"\n",
        "\n",
        "**Can you find and describe some property in the filters that makes sense when it comes to separating \"5\" from \"6\"?**\n",
        "\n",
        "Hint! If you repeat the training you most likely get a new network and other filters!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The index of the input image to show\n",
        "idx = 5\n",
        "\n",
        "# The names of the layers to visualize\n",
        "layers_vis = [\"act1\", \"act2\"]\n",
        "\n",
        "# Call the visualization method, giving the model and the validation data to display\n",
        "layerVisualization(model_ex1, layers_vis, x_val, d_val, idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "slideshow": {
          "slide_type": ""
        },
        "tags": []
      },
      "source": [
        "# CellName: Ex3 (#12)\n",
        "**CellType: Exercise**  \n",
        "**Cell instruction: Instructions for question 4-5**\n",
        "\n",
        "## CNN for image classification\n",
        "\n",
        "In this exercise you are going to train a CNN that can separate between circles/squares/triangles found in the CRT dataset, and the three different types of rectangles found in the R3 dataset. You will use 500 training images and 1000 validation images. Code is provided for loading the data, training the model and presenting the result. Your task is to define the actual CNN model and see how it performs. For the following two questions you can optimize the model based on the validation performance. Here we assume that 1000 validation images are many enough for \"model selection overtraining bias\" to be small.\n",
        "\n",
        "### Question 4\n",
        "Define your own CNN model for classifying the images in the CRT data into three classes. **Provide the details of your CNN model and present the validation result.**\n",
        "\n",
        "**Hint:** Remember the difference between a binary classifier and a multi-class classifier!\n",
        "After the last layer, you will need a layer with `nn.Softmax(dim=1)`. (Here dim is the dimension that will be softmaxed; dim=0 would refer to the index of the input data in the mini-batch.)\n",
        "\n",
        "### Question 5\n",
        "Define your own CNN model for classifying the images in the R3 data into three classes. **Provide the details of your CNN model and present the validation result.** **Why is this a more difficult problem than Question 4?**\n",
        "\n",
        "\n",
        "### Bonus task \n",
        "The bonus tasks are provided if you have extra time and want to continue to explore the CNNs. **These tasks are not required for the course and does not influence any grading**. \n",
        "\n",
        "You can use the `layerVisualization` method also for the above models (Q4 and Q5). It will show you the different filter outputs. Again try to understand the features the different filter learn to separate between circles-triangles-rectangles, or the rectangles for the R3 dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the CRT dataset (Question 4)\n",
        "x_trn, d_trn, x_val, d_val, width, height = loadImagesCRT()\n",
        "\n",
        "# Load the R3 dataset (Question 5)\n",
        "#x_trn, d_trn, x_val, d_val, width, height = loadImagesR3()\n",
        "\n",
        "print('Training data input shape: ', x_trn.shape)\n",
        "print('Training data output shape: ', d_trn.shape)\n",
        "print('Validation data input shape: ', x_val.shape)\n",
        "print('Validation data output shape: ', d_val.shape)\n",
        "\n",
        "# Container for CNN layers that will be used to construct the Network\n",
        "layers = OrderedDict()\n",
        "\n",
        "#\n",
        "# YOUR CODE HERE\n",
        "#\n",
        "\n",
        "model_ex3 = Network(layers, l2regularization=0).to(device)\n",
        "\n",
        "# Hyperparameters\n",
        "opt_method = torch.optim.Adam   # minimization method\n",
        "learning_rate = 0.003           # learning rate\n",
        "loss_fn = nn.CrossEntropyLoss() # loss function, categorical cross entropy\n",
        "number_epochs = 50\n",
        "minibatch_size = 50\n",
        "\n",
        "# Additional metrics to print {name: metric}\n",
        "metrics = {'accuracy': ClassificationAccuracyMetric()}\n",
        "\n",
        "# Print a summary of the model\n",
        "print(model_ex3)\n",
        "\n",
        "# Set up the optimizer\n",
        "optimizer = opt_method(model_ex3.parameters(), lr=learning_rate)\n",
        "\n",
        "# Create datasets and batch loaders for the training and test data on the GPU or CPU\n",
        "dset_trn = TensorDataset(torch.tensor(x_trn, device=device, dtype=dtype_torch),\n",
        "                         torch.tensor(d_trn, device=device, dtype=dtype_torch))\n",
        "dl_trn = DataLoader(dset_trn, batch_size=minibatch_size, shuffle=True)\n",
        "\n",
        "dset_val = TensorDataset(torch.tensor(x_val, device=device, dtype=dtype_torch),\n",
        "                         torch.tensor(d_val, device=device, dtype=dtype_torch))\n",
        "dl_val = DataLoader(dset_val)\n",
        "\n",
        "\n",
        "# Train the network and print the progress\n",
        "train_loss, val_loss, metrics_res = train_loop(\n",
        "    model=model_ex3,\n",
        "    train_dataloader=dl_trn,\n",
        "    val_dataloader=dl_val,\n",
        "    loss_fn=loss_fn,\n",
        "    metrics=metrics,\n",
        "    optimizer=optimizer,\n",
        "    print_every=5,\n",
        "    epochs=number_epochs)\n",
        "\n",
        "# Plot the training history\n",
        "plot_training(train_loss, val_loss, metrics_res)\n",
        "\n",
        "# Plot confusion matrix and print some classification statistics\n",
        "make_cm_plot(model_ex3, x_val, d_val, \"Validation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The index of the input image to show\n",
        "idx = 5\n",
        "\n",
        "# The names of the layers to visualize\n",
        "layers_vis = [\"act1\"]\n",
        "\n",
        "# Call the visualization method, giving the model and the validation data to display\n",
        "layerVisualization(model_ex3, layers_vis, x_val, d_val, idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "slideshow": {
          "slide_type": ""
        },
        "tags": []
      },
      "source": [
        "# CellName: Ex4-1 (#13)\n",
        "**CellType: Exercise**  \n",
        "**Cell instruction: Instructions for question 6-9**\n",
        "\n",
        "## RNN as a pulse converter\n",
        "We will now look at recurrent networks! **Note**: This exercise is divided into three cells. The actual questions for this part can be found in cell *Ex4-3* below.\n",
        "\n",
        "### Loading and visualizing the data\n",
        "The cell below loads the training data and the validation data from existing binary python files and plots one set of training/validation data, both the input sequence and the target sequence. Run the cell by entering into the cell and press \"CTRL Enter\".\n",
        "\n",
        "How is data generated? The input sequence consists of square pulses with varying length and height. The waiting time between the pulses is also varying within some predefined ranges. The lower limit is 2 times the length of the previous pulse. The target triangle pulse sequence is built from the input sequence as follows:\n",
        "* the triangle pulse starts when the input square pulse have ended.\n",
        "* the width of the triangle (at the base) is twice the width of the square pulse.\n",
        "* the height of the triangle is the same as the height of the square pulse.\n",
        "\n",
        "The task is now to learn this mapping using a recurrent neural network. There are 500 input/target sequences in the training data and 500 in the validation data, with a sequence length of 100 samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data from files\n",
        "x_trn, d_trn = np.load(\"pulsedata1-trn.npy\")\n",
        "x_val, d_val = np.load(\"pulsedata1-val.npy\")\n",
        "\n",
        "# Uncomment below to load data for the bonus task\n",
        "#x_trn, d_trn = np.load(\"pulsedata2-trn.npy\")\n",
        "#x_val, d_val = np.load(\"pulsedata2-val.npy\")\n",
        "\n",
        "print('Training data input shape:', x_trn.shape)\n",
        "print('Training data output shape:', d_trn.shape)\n",
        "print('Validation data input shape:', x_val.shape)\n",
        "print('Validation data output shape:', d_val.shape)\n",
        "\n",
        "# If this is set to True, then we have the reverse problem. Input triangle pulse, target square puls.\n",
        "if False:\n",
        "    # Torch doesn't like arrays with negative stride so we reverese+copy the data\n",
        "    d_trn, x_trn = x_trn[:,::-1].copy(), d_trn[:,::-1].copy()\n",
        "    d_val, x_val = x_val[:,::-1].copy(), d_val[:,::-1].copy()\n",
        "\n",
        "ns, tlen = x_trn.shape\n",
        "t = np.arange(tlen)\n",
        "\n",
        "# The training / test case to look at\n",
        "i = 3\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(15, 10), tight_layout=True)\n",
        "plt.subplot(4,1,1)\n",
        "plt.plot(t, x_trn[i,:])\n",
        "plt.legend(['Training, input sequence'], loc=0)\n",
        "\n",
        "plt.subplot(4,1,2)\n",
        "plt.plot(t, d_trn[i,:])\n",
        "plt.legend(['Training, target sequence'], loc=0)\n",
        "\n",
        "plt.subplot(4,1,3)\n",
        "plt.plot(t, x_val[i,:])\n",
        "plt.legend(['Validation, input sequence'], loc=0)\n",
        "\n",
        "plt.subplot(4,1,4)\n",
        "plt.plot(t, d_val[i,:])\n",
        "plt.legend(['Validation, target sequence'], loc=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "slideshow": {
          "slide_type": ""
        },
        "tags": []
      },
      "source": [
        "# CellName: Ex4-2 (#14)\n",
        "**CellType: Exercise**  \n",
        "**Cell instruction: Instructions for question 6-9**\n",
        "\n",
        "## RNN as a pulse converter\n",
        "### Define the model and train\n",
        "Here we are going to set up the model and train it. The network class and training functions are defined in cell #8. There are three different models to choose from: \n",
        "* `nn.RNN`: Simple feedback weights where the output from a node is feeding back to itself. With several hidden nodes there are feedback weights to all other nodes in the layer.\n",
        "* `nn.LSTM`: The LSTM unit\n",
        "* `nn.GRU`: The GRU unit\n",
        "\n",
        "When we say \"RNN\" in this notebook, we generally mean RNNs in general unless it's clear that we're referring to the \"simple\" RNN networks (i.e., `nn.RNN`).\n",
        "\n",
        "The standard choice of activation function for `nn.RNN` is *tanh*, but you can also test *relu* (see the code below). When training this model, we will use a possible truncated BPTT approach, as defined in cell #8. In short, we have 500 training sequences, and we define a mini-batch size (*minibatch_size*) that selects *minibatch_size* of these sequences to train using the normal stochastic gradient descent idea. We then have a variable *truncationlen*, which is the length of the sequence to use in truncated BPTT. The default values for these are *minibatch_size=20* and *truncationlen=25*. If you want to train without the truncated BPTT approach, put *truncationlen=100*.\n",
        "\n",
        "During training, we print the normalized training and validation error. Normalized means here that the loss (=MSE) is divided by the variance of the target signal. That means that a normalized error of 1 is poor, but below 0.1 (or so) the error is much smaller than the signal itself.\n",
        "\n",
        "What you need to do in this cell is to define your model and train it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "# The network type\n",
        "net = nn.RNN\n",
        "# net = nn.GRU\n",
        "# net = nn.LSTM\n",
        "\n",
        "# Number of hidden nodes (as a list if you want 2 or more layers)\n",
        "nhidden = [5]\n",
        "\n",
        "netargs = {}\n",
        "# Uncomment below if you want ReLU for the simple nn.RNN network\n",
        "# netargs['nonlinearity'] = 'relu'\n",
        "\n",
        "model_ex4 = StatefulNetwork(net, nodes=nhidden, **netargs).to(device)\n",
        "\n",
        "# Hyperparameters\n",
        "opt_method = torch.optim.Adam   # minimization method\n",
        "learning_rate = 0.003           # learning rate\n",
        "loss_fn = nn.MSELoss()          # loss function, binary cross entropy\n",
        "number_epochs = 25\n",
        "minibatch_size = 20\n",
        "truncationlen = 25\n",
        "\n",
        "# Print a summary of the model\n",
        "print(model_ex4)\n",
        "\n",
        "# Set up the optimizer\n",
        "optimizer = opt_method(model_ex4.parameters(), lr=learning_rate)\n",
        "\n",
        "# Create datasets and batch loaders for the training and test data on the GPU or CPU\n",
        "dset_trn = TensorDataset(torch.tensor(x_trn[..., None], device=device, dtype=dtype_torch),\n",
        "                         torch.tensor(d_trn[..., None], device=device, dtype=dtype_torch))\n",
        "dl_trn = DataLoader(dset_trn, batch_size=minibatch_size, shuffle=True)\n",
        "\n",
        "dset_val = TensorDataset(torch.tensor(x_val[..., None], device=device, dtype=dtype_torch),\n",
        "                         torch.tensor(d_val[..., None], device=device, dtype=dtype_torch))\n",
        "dl_val = DataLoader(dset_val)\n",
        "\n",
        "# Train the network and print the progress\n",
        "train_loss, val_loss = train_TBPTT(\n",
        "    model_ex4,\n",
        "    epochs=number_epochs,\n",
        "    truncationlen=truncationlen,\n",
        "    train_dataloader=dl_trn,\n",
        "    val_dataloader=dl_val,\n",
        "    loss_fn=loss_fn,\n",
        "    optimizer=optimizer,\n",
        "    print_every=5\n",
        "    )\n",
        "\n",
        "# Plot the training history\n",
        "plot_training(train_loss, val_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "slideshow": {
          "slide_type": ""
        },
        "tags": []
      },
      "source": [
        "# CellName: Ex4-3 (#15)\n",
        "**CellType: Exercise**  \n",
        "**Cell instruction: Instructions for question 6-9**\n",
        "\n",
        "## RNN as a pulse converter\n",
        "### Plot the result\n",
        "In this cell we just plot the result for one of the first validation sequences. You can select which of these ones by an index (see the code).\n",
        "\n",
        "## Questions\n",
        "We are now finally at the point of asking questions. Whenever you define a new model and train it, you need to run the cell below to display the result for the newly trained model. \n",
        "\n",
        "**Hint:** For all of the questions below, you will train different models. Keep an eye on how the training error is developing. If you see large fluctuations, you may to change the learning rate. The default value of 0.003 should be OK for most trainings. \n",
        "\n",
        "### Question 6\n",
        "(Just to get started!) Define a simple RNN model with 5 hidden nodes and train it for about 25 epochs. **What validation error do you obtain?** \n",
        "\n",
        "**Hint:** You may have to train a couple of times to make sure that you did not end up in a \"bad\" local minimum the first time.\n",
        "\n",
        "### Question 7\n",
        "Test different models! Train the three different models (one hidden layer only) with the approximately the same number of trainable weights (around 150-200) and decide which of them that works best? **So, out of the three different models, *RNN*, *GRU* and *LSTM*, which one worked best using (approximately) the same number of weights?**\n",
        "\n",
        "### Question 8\n",
        "If you look at the top of cell *Ex4-1* you can, by changing False -> True, define the reverse problem (see top of the code cell). That is, input is the triangle pulse and target is the square pulse. This should be a more difficult problem! **Why?** **Present a RNN model that can \"solve\" this reverse problem (i.e. aim for a validation error below 0.05).**\n",
        "\n",
        "**Hint:** Here you can experiment with two hidden layers of LSTM, GRU or simple RNN nodes\n",
        "\n",
        "### Bonus task \n",
        "The bonus task is provided if you have extra time and would like to test a more challenging problem. **This task is not required for the course and does not influence any grading**. \n",
        "\n",
        "At the top of cell *Ex4-1*, you can uncomment the lines that read data for this bonus task. \n",
        "This is similar to the first pulse conversion problem with a few modifications: \n",
        "\n",
        "* the sample length is now 200.\n",
        "* the triangle pulse starts when the square pulse has ended.\n",
        "* the width of the triangle (at the base) depends on the two previous square pulses. The width is the mean of the widths of the two previous pulses.\n",
        "* the height of the triangle depends on the two previous square pulses. The height is the mean of the heights of the two previous pulses.\n",
        "* for the first triangle pulse, it is based on the previous square pulse only!\n",
        "\n",
        "You can look at the new data in cell *Ex4-1*.\n",
        "\n",
        "### Bonus question\n",
        "Find the smallest model that can reach below **0.01** validation error. You may need to adjust the *minibatch_size*, *truncation_len*, and *learning_rate* hyperparameters to optimize the training.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "editable": true,
        "slideshow": {
          "slide_type": ""
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "i = 7\n",
        "plt.figure(figsize=(15, 10), tight_layout=True)\n",
        "plt.subplot(4,1,1)\n",
        "plt.plot(t, x_trn[i,:], label='Training, input sequence')\n",
        "plt.legend(loc=0)\n",
        "\n",
        "plt.subplot(4,1,2)\n",
        "plt.plot(t, d_trn[i,:], label='Training, target sequence')\n",
        "pred = model_ex4.predict(x_trn[i,:,None])\n",
        "plt.plot(t, pred[:,0], label='Training, output sequence')\n",
        "plt.legend(loc=0)\n",
        "\n",
        "plt.subplot(4,1,3)\n",
        "plt.plot(t, x_val[i,:], label='Validation, input sequence')\n",
        "plt.legend(loc=0)\n",
        "\n",
        "plt.subplot(4,1,4)\n",
        "plt.plot(t, d_val[i,:], label='Validation, target sequence')\n",
        "pred = model_ex4.predict(x_val[i,:,None])\n",
        "plt.plot(t, pred[:,0], label='Validation, output sequence')\n",
        "plt.legend(loc=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "slideshow": {
          "slide_type": ""
        },
        "tags": []
      },
      "source": [
        "# The report!\n",
        "\n",
        "We have added intructions inside this report template. As you write your report, remove the instructions.\n",
        "\n",
        "## Name\n",
        "\n",
        "## Introduction\n",
        "A few sentences about the overall theme of the exercise.\n",
        "\n",
        "## Answers to questions\n",
        "Provide enough information to clarify the meaning of your answers, so that they can be understood by someone who does not scroll up and read the entire instruction.\n",
        "\n",
        "The questions are repeated here, for clarity of what is demanded. If it does not fit your style to quote them verbatim, change the format.\n",
        "\n",
        "**Question 1**, CNN training  \n",
        "What is your validation set performance in terms of the accuracy?\n",
        "\n",
        "**Question 2**, model optimization  \n",
        "How many parameters do you have in your trimmed model? What is your architecture?\n",
        "\n",
        "**Question 3**, filter interpretation  \n",
        "Can you find and describe some property in the filters that makes sense when it comes to separating \"5\" from \"6\"?\n",
        "\n",
        "**Question 4**, CNN classification  \n",
        "Provide the details of your CNN model for the CRT problem and present the validation result.\n",
        "\n",
        "**Question 5**, harder classification  \n",
        "Provide the details of your CNN model for the R3 problem and present the validation result.  \n",
        "Why is this a more difficult problem than Question 4?\n",
        "\n",
        "**Question 6**, RNN training  \n",
        "What validation error do you obtain?\n",
        "\n",
        "**Question 7**, RNN type comparison  \n",
        "Present three different models, *RNN*, *GRU* and *LSTM*, using roughly the same number of weights.  \n",
        "Which one worked best?\n",
        "\n",
        "**Question 8**, harder RNN problem  \n",
        "**(a)** Why is the reverse of the pulse problem (input signal and target signal change roles, time is reversed) more difficult?  \n",
        "**(b)** Present a RNN model that can \"solve\" this reverse problem (i.e. below 0.05 in test error).\n",
        "\n",
        "\n",
        "## Summary\n",
        "Connect the summary to your introduction, to provide a brief overview of your findings.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {
        "height": "530px",
        "width": "356.167px"
      },
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}